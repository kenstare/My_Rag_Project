{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90320f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import glob\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.prompts import MessagesPlaceholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "104f618b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in .env file\")\n",
    "\n",
    "print(\"API key loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b7bcac",
   "metadata": {},
   "source": [
    "#### Documents collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13885487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7 pages from PDFs\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "for pdf_path in glob.glob(\"documents/*.pdf\"):  # adjust folder path\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    docs = loader.load()\n",
    "    documents.extend(docs)\n",
    "\n",
    "print(f\"Loaded {len(documents)} pages from PDFs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83da7f4",
   "metadata": {},
   "source": [
    "#### Text Splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b47191d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 7 documents into 34 chunks\n",
      "\n",
      "Chunk 1: AI & ML Projects\n",
      "AI & ML Projects\n",
      "AI & ML Projects (Combined)\n",
      "AI & ML Projects (updated)\n",
      "AI & ML Projects (Updated)\n",
      "Project 1: World Population Forecast\n",
      "- Objective: Forecast world population trends using demographic and\n",
      "socio-economic data.\n",
      "\n",
      "Chunk 2: - Methods: Time series modeling, ARIMA, Prophet, LSTM/Transformer sequence\n",
      "models.\n",
      "- Data sources: UN population estimates, World Bank indicators.\n",
      "Project 2: Predicting Food Prices in Nigeria\n",
      "- Objective: Build models to predict food price movements in Nigerian markets.\n",
      "\n",
      "Chunk 3: - Methods: Regression models, tree-based models (XGBoost/LightGBM), temporal\n",
      "models.\n",
      "- Features: Supply indicators, weather, inflation, transport costs, seasonality.\n",
      "Project 3: Indian Credit Card / Car Price Predicting\n",
      "\n",
      "Chunk 4: - Objective: Predict credit card default risk and car price/value estimation in Indian\n",
      "markets.\n",
      "- Methods: Classification for credit risk; regression for car price prediction using\n",
      "features like year, mileage, make/model, region.\n",
      "\n",
      "Chunk 5: - Data sources: Public datasets, scraped market listings, financial records.\n",
      "Cloud Computing (Added to projects and personal info)\n",
      "- Overview: Cloud resources and patterns useful for deploying ML workloads and\n",
      "data pipelines.\n",
      "- Key services to know and practice:\n",
      "\n",
      "Chunk 6: - Amazon EC2: Launch and manage virtual server instances for model training and\n",
      "inference.\n",
      "- Amazon S3: Store datasets, model artifacts, and logs with lifecycle rules and\n",
      "versioning.\n",
      "- Amazon VPC: Create isolated networks, subnets, routing tables, security groups\n",
      "for secure deployments.\n",
      "\n",
      "Chunk 7: - IAM: Manage users, roles, and policies for least-privilege access.\n",
      "- Auto Scaling & Load Balancing: Scale model serving and APIs for availability and\n",
      "cost-efficiency.\n",
      "- RDS / DynamoDB: Managed databases for metadata and application state.\n",
      "\n",
      "Chunk 8: - AWS Lambda & Step Functions: Serverless orchestration for lightweight tasks\n",
      "and ETL.\n",
      "- Suggested hands-on tasks:\n",
      "1. Create an S3 bucket, upload sample datasets, enable versioning.\n",
      "\n",
      "Chunk 9: 2. Launch an EC2 instance, install Python + ML stack, run a small training job.\n",
      "3. Set up a VPC with public and private subnets, attach a security group permitting\n",
      "only necessary ports.\n",
      "4. Create IAM roles for EC2 and for a CI/CD pipeline with least privilege.\n",
      "\n",
      "Chunk 10: 5. Deploy a simple model behind an Application Load Balancer with an Auto\n",
      "Scaling Group.\n",
      "- Notes:\n",
      "- Follow best practices for credentials: use IAM roles, avoid embedding secrets,\n",
      "rotate keys.\n",
      "- Consider cost management: use spot instances for training, lifecycle policies for\n",
      "S3.\n",
      "\n",
      "Chunk 11: S3.\n",
      "Cloud_Computing_Info\n",
      "Cloud Computing â€” Practical Guide for Personal Info\n",
      "This document provides hands-on tasks and brief explanations to add cloud\n",
      "computing skills to your profile.\n",
      "Core Concepts\n",
      "- EC2: Virtual machines. Use for training small models, experimenting, and running\n",
      "containers.\n",
      "\n",
      "Chunk 12: containers.\n",
      "- S3: Object storage. Store raw data, preprocessed datasets, model checkpoints,\n",
      "and logs.\n",
      "- VPC: Virtual Private Cloud to isolate resources, create private subnets for\n",
      "databases, public subnets for load balancers.\n",
      "\n",
      "Chunk 13: - IAM: Identity and Access Management for users, groups, roles, and policies.\n",
      "- Autoscaling & ELB: Keep services available and scale according to load.\n",
      "Getting started (practical steps)\n",
      "1. Create an S3 bucket; upload a sample CSV dataset; enable versioning and set a\n",
      "\n",
      "Chunk 14: lifecycle rule to archive older data.\n",
      "2. Launch an EC2 instance (Ubuntu 22.04), SSH in, install Python, pip, and\n",
      "common ML libraries (numpy, pandas, scikit-learn, torch/tensorflow).\n",
      "3. Configure an IAM role for the EC2 instance with S3 read/write permissions\n",
      "\n",
      "Chunk 15: (avoid storing AWS keys on the instance).\n",
      "4. Design a VPC: create subnets, route tables, an internet gateway for public\n",
      "subnet; put databases in private subnet.\n",
      "5. Deploy a small Flask/FastAPI model server on EC2 and put it behind an\n",
      "Application Load Balancer. Configure an Auto Scaling Group.\n",
      "\n",
      "Chunk 16: 6. (Optional) Use AWS Lambda + Step Functions for scheduled ETL jobs that\n",
      "move data from S3 to a database.\n",
      "Security & Cost\n",
      "- Use Security Groups to restrict inbound traffic.\n",
      "- Use IAM roles with least privilege.\n",
      "- Monitor costs; use AWS Cost Explorer and set budgets/alerts.\n",
      "\n",
      "Chunk 17: - Use spot instances for large training jobs to reduce costs.\n",
      "\n",
      "Chunk 18: Personal Biography\n",
      "I am Kehinde Akindele, an Art student specializing in Graphic Design and visual\n",
      "communication, with a growing focus on Artificial Intelligence engineering and\n",
      "Cloud Computing. I approach design as both a creative and technical discipline,\n",
      "\n",
      "Chunk 19: blending artistic expression with modern technologies to build intelligent and\n",
      "scalable digital solutions.\n",
      "Born in August and proudly from Ekiti State, Nigeria, my background and\n",
      "environment have shaped my creative mindset and curiosity for innovation. These\n",
      "\n",
      "Chunk 20: influences guide my approach to design, where visual storytelling meets\n",
      "technology.\n",
      "Currently, I am learning AI engineering, exploring how machine learning,\n",
      "data-driven models, and AI-powered tools can enhance creativity, automate\n",
      "\n",
      "Chunk 21: workflows, and solve real-world problems. Alongside this, I am developing cloud\n",
      "computing skills to support deployment, scalability, and collaboration. My goal is to\n",
      "grow into a multidisciplinary professional who combines art, design, AI, and cloud\n",
      "\n",
      "Chunk 22: technology to create impactful and future-ready solutions.\n",
      "\n",
      "Chunk 23: Kehinde Akindele\n",
      "AI Engineer & Data Scientist\n",
      "Professional Summary\n",
      "AI Engineer with a strong background in mathematics, data science, and applied machine\n",
      "learning. Specializes in building intelligent systems that combine predictive modeling,\n",
      "\n",
      "Chunk 24: natural language processing, and data-driven decision-making. Experienced in designing,\n",
      "training, and deploying machine learning models.\n",
      "Education\n",
      "M.Sc. Artificial Intelligence; B.Sc. Applied Mathematics\n",
      "Technical Skills\n",
      "- Programming: Python, SQL, JavaScript\n",
      "\n",
      "Chunk 25: - Machine Learning: Regression, Classification, Time-Series Forecasting\n",
      "- Deep Learning: Neural Networks, Transformers\n",
      "- NLP: Text Embeddings, Vector Databases, RAG Systems\n",
      "- Tools: LangChain, Chroma, PyTorch, TensorFlow, Docker, Git\n",
      "Experience\n",
      "\n",
      "Chunk 26: Experience\n",
      "- Built predictive models for sales forecasting in e-commerce\n",
      "- Developed AI-powered chatbots for document-based question answering\n",
      "- Designed REST APIs for ML model deployment using Flask/FastAPI\n",
      "Research Interests\n",
      "\n",
      "Chunk 27: Research Interests\n",
      "Retrieval-Augmented Generation (RAG), large language models, time-series forecasting,\n",
      "and AI system deployment. Interested in ethical AI and model interpretability.\n",
      "Teaching & Mentorship\n",
      "- Algebra, Calculus, and Probability\n",
      "- Python programming for beginners\n",
      "\n",
      "Chunk 28: - Machine learning fundamentals\n",
      "- Data analysis using Python and Excel\n",
      "Email: akindekekehinde250@gmail.com | GitHub:\n",
      "https://github.com/kenstare?tab=repositories\n",
      "\n",
      "Chunk 29: My  research  interests  lie  in  building  intelligent  systems  that  combine  information  retrieval  and  language  understanding.  I  am  particularly  interested  in  Retrieval-  Augmented  Generation  (RAG)  systems  and  their  applications  in  education  and  finance.   My  long-term  goal\n",
      "\n",
      "Chunk 30: My  long-term  goal  is  to  become  a  lead  AI  engineer,  designing  scalable  AI  platforms  that  assists  decision-making.  I  aim  to  contribute  to  AI  research  while  also  building  practical  tools  that  solve  real-world  problems.   I  am  passionate  about  ethical  AI,  model\n",
      "\n",
      "Chunk 31: AI,  model  interpretability,  and  making  AI  accessible  to  non-technical  users.\n",
      "\n",
      "Chunk 32: I  have  extensive  experience  teaching  mathematics  and  programming  to  high  school  and  undergraduate  students.  I  conduct  online  classes  using  Google  Meet  and  Zoom,  focusing  on  clarity,  problem-solving,  and  real-world  applications.   Subjects  taught  include:  -  Algebra,\n",
      "\n",
      "Chunk 33: -  Algebra,  Calculus,  and  Probability  -  Python  programming  for  beginners  -  Machine  learning  fundamentals  -  Data  analysis  using  Python  and  Excel   I  also  mentor  students  working  on  AI  and  data  science  projects,  guiding  them  through  problem  formulation,  model\n",
      "\n",
      "Chunk 34: model  selection,  and  evaluation  techniques.\n"
     ]
    }
   ],
   "source": [
    "# Create splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "# Split documents\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Split {len(documents)} documents into {len(chunks)} chunks\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\nChunk {i+1}: {chunk.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf97faa",
   "metadata": {},
   "source": [
    "#### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d24ed5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 1536\n",
      "First 5 values: [0.0006281227106228471, 0.02569717727601528, 0.007161187008023262, 0.03336399793624878, -0.031968604773283005]\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key=api_key\n",
    ")\n",
    "\n",
    "# Test embedding\n",
    "test_embedding = embeddings.embed_query(\"What is RAG?\")\n",
    "print(f\"Embedding dimension: {len(test_embedding)}\")\n",
    "print(f\"First 5 values: {test_embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48504251",
   "metadata": {},
   "source": [
    "#### Vector Store\n",
    "# Create vector store from documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8151c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    chunks,\n",
    "    embeddings,\n",
    "    collection_name=\"my_info_collection\",\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5339b8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': '(anonymous)', 'page': 0, 'creator': '(unspecified)', 'keywords': '', 'total_pages': 1, 'page_label': '1', 'subject': '(unspecified)', 'source': 'documents\\\\Personal Biography.pdf', 'trapped': '/False', 'author': '(anonymous)', 'moddate': '2025-12-14T19:10:01+01:00', 'creationdate': '2025-12-14T19:10:01+01:00', 'producer': 'ReportLab PDF Library - (opensource)'}, page_content='workflows, and solve real-world problems. Alongside this, I am developing cloud\\ncomputing skills to support deployment, scalability, and collaboration. My goal is to\\ngrow into a multidisciplinary professional who combines art, design, AI, and cloud'),\n",
       " Document(metadata={'page_label': '1', 'keywords': '', 'creator': '(unspecified)', 'author': '(anonymous)', 'subject': '(unspecified)', 'page': 0, 'producer': 'ReportLab PDF Library - (opensource)', 'source': 'documents\\\\Personal Biography.pdf', 'moddate': '2025-12-14T19:10:01+01:00', 'creationdate': '2025-12-14T19:10:01+01:00', 'title': '(anonymous)', 'total_pages': 1, 'trapped': '/False'}, page_content='workflows, and solve real-world problems. Alongside this, I am developing cloud\\ncomputing skills to support deployment, scalability, and collaboration. My goal is to\\ngrow into a multidisciplinary professional who combines art, design, AI, and cloud'),\n",
       " Document(metadata={'author': '(anonymous)', 'subject': '(unspecified)', 'moddate': '2025-12-14T19:10:01+01:00', 'creator': '(unspecified)', 'page': 0, 'keywords': '', 'source': 'documents\\\\Personal Biography.pdf', 'total_pages': 1, 'page_label': '1', 'title': '(anonymous)', 'producer': 'ReportLab PDF Library - (opensource)', 'creationdate': '2025-12-14T19:10:01+01:00', 'trapped': '/False'}, page_content='workflows, and solve real-world problems. Alongside this, I am developing cloud\\ncomputing skills to support deployment, scalability, and collaboration. My goal is to\\ngrow into a multidisciplinary professional who combines art, design, AI, and cloud')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test retriver\n",
    "query = \"Technical skills\"\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "results = retriever.invoke(query)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e8510f",
   "metadata": {},
   "source": [
    "#### Conversational Rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1955fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    openai_api_key=api_key\n",
    ")\n",
    "\n",
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 2}\n",
    ")\n",
    "\n",
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an AI assistant answering questions about Kehinde Akindele using the provided documents.\n",
    "\n",
    "Use ONLY the context below to answer the question.\n",
    "If the answer is not in the context, say \"I don't know.\"\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer in clear sentences.\n",
    "At the end, list the sources you used as bullet points.\n",
    "\"\"\")\n",
    "\n",
    "# format documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(\n",
    "        f\"Source: {doc.metadata.get('source', 'unknown')}\\n{doc.page_content}\"\n",
    "        for doc in docs\n",
    "    )\n",
    "\n",
    "# RAG chain Using LCEL\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "211787ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kehinde Akindele has worked on AI projects that involve building intelligent systems combining predictive modeling. Specific details about the AI projects are not provided in the context.\n",
      "\n",
      "Sources:\n",
      "- documents\\Professional Resume.pdf\n"
     ]
    }
   ],
   "source": [
    "query = \"What AI projects has Kehinde worked on?\"\n",
    "response = rag_chain.invoke(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1062785b",
   "metadata": {},
   "source": [
    "#### Conversational RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12079bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store for chat histories\n",
    "chat_store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in chat_store:\n",
    "        chat_store[session_id] = InMemoryChatMessageHistory()\n",
    "    return chat_store[session_id]\n",
    "\n",
    "# Create conversational prompt\n",
    "conv_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant answering questions about Kehinde Akindele using the provided documents. Use ONLY the context below to answer the question. If the answer is not in the context, say I don't know.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"system\", \"Answer in clear sentences. At the end, list the sources you used as bullet points.\"),\n",
    "    (\"human\", \"Context: {context}\\n\\nQuestion: {question}\")\n",
    "])\n",
    "\n",
    "# Build base chain\n",
    "conv_chain_base = (\n",
    "    RunnableParallel(\n",
    "        context=lambda x: format_docs(retriever.invoke(x[\"question\"])),\n",
    "        question=lambda x: x[\"question\"],\n",
    "        chat_history=lambda x: x.get(\"chat_history\", [])\n",
    "    )\n",
    "    | conv_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Wrap with message history\n",
    "conv_chain = RunnableWithMessageHistory(\n",
    "    conv_chain_base,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"chat_history\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdecec4",
   "metadata": {},
   "source": [
    "\n",
    "**Questions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec58bd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1:\n",
      " Kehinde Akindele has worked on projects related to Graphic Design, visual communication, Artificial Intelligence engineering, and Cloud Computing.\n",
      "\n",
      "Response 2:\n",
      " Kehinde Akindele has worked on projects involving RAG Systems in the areas of building predictive models for sales forecasting in e-commerce, developing AI-powered chatbots for document-based question answering, and designing REST APIs for ML models.\n",
      "\n",
      "Sources:\n",
      "- Professional Resume.pdf\n"
     ]
    }
   ],
   "source": [
    "# First question\n",
    "response = conv_chain.invoke(\n",
    "    {\"question\": \"What projects has Kehinde worked on?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user_1\"}}\n",
    ")\n",
    "print(\"Response 1:\\n\", response)\n",
    "\n",
    "# Follow-up question\n",
    "response2 = conv_chain.invoke(\n",
    "    {\"question\": \"Which of those involve RAG systems?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user_1\"}}\n",
    ")\n",
    "\n",
    "print(\"\\nResponse 2:\\n\", response2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-1 (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
